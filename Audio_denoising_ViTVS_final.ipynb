{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f638bc4e",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f988b40f-8ba6-4da5-8880-070e90a27db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import requests\n",
    "import time\n",
    "import pickle\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch and related libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_tensor, resize\n",
    "from torchvision import transforms as TF\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import torchmetrics as TM\n",
    "from torch.nn import Fold\n",
    "\n",
    "\n",
    "\n",
    "# Transformers library\n",
    "from transformers import get_scheduler\n",
    "\n",
    "# Sklearn for metrics\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "\n",
    "# PIL for image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Visualization libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Additional utilities\n",
    "from typing import Sequence\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import dataclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db47ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from the PIL library\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Set constant values for image size and batch size\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "927c1728-295d-4985-bfc0-57980d6b2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDenoisingDataset(Dataset):\n",
    "    \"\"\"Custom dataset for audio denoising task.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): Directory containing input images.\n",
    "        masks_dir (str): Directory containing corresponding masks.\n",
    "        transform (callable, optional): Optional transform to be applied on the input images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.images = [img for img in os.listdir(images_dir) if img.endswith('.png')]\n",
    "        self.masks = [mask.replace('.png', '.png') for mask in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the input image and its corresponding mask.\n",
    "        \"\"\"\n",
    "        image_path = os.path.join(self.images_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert('L')  # Convert mask to grayscale\n",
    "\n",
    "        # Convert mask to binary format with 0 and 1 values\n",
    "        mask = np.array(mask)\n",
    "        mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "        # Convert to PIL Image for consistency in transforms\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Resize the mask to the desired image size\n",
    "        mask = resize(mask, size=[IMG_SIZE, IMG_SIZE], interpolation=Image.Resampling.NEAREST)\n",
    "        mask = TF.functional.to_tensor(mask)\n",
    "        mask = (mask > 0).long()  # Threshold back to binary and convert to LongTensor\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef43d5f1-4663-420d-bad9-96f30c291035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the appropriate transformations\n",
    "transform = TF.Compose([\n",
    "    TF.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    # Uncomment the following lines if normalization is needed\n",
    "    # TF.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    TF.ToTensor()\n",
    "])\n",
    "\n",
    "# Define the dataset paths\n",
    "# Train part\n",
    "train_images_dir = 'dataset/Train/Images'\n",
    "train_masks_dir = 'dataset/Train/Masks'\n",
    "\n",
    "# Validation part\n",
    "valid_images_dir = 'dataset/Valid/Images'\n",
    "valid_masks_dir = 'dataset/Valid/Masks'\n",
    "\n",
    "# Test part\n",
    "test_images_dir = 'dataset/Test/Images'\n",
    "test_masks_dir = 'dataset/Test/Masks'\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = AudioDenoisingDataset(images_dir=train_images_dir,\n",
    "                                      masks_dir=train_masks_dir,\n",
    "                                      transform=transform)\n",
    "\n",
    "valid_dataset = AudioDenoisingDataset(images_dir=valid_images_dir,\n",
    "                                      masks_dir=valid_masks_dir,\n",
    "                                      transform=transform)\n",
    "\n",
    "test_dataset = AudioDenoisingDataset(images_dir=test_images_dir,\n",
    "                                     masks_dir=test_masks_dir,\n",
    "                                     transform=transform)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad9074af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(preds, labels, num_classes):\n",
    "    \"\"\"Calculate the mean F1 score for multiple classes.\n",
    "\n",
    "    Args:\n",
    "        preds (torch.Tensor): Predicted labels (logits) from the model.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "        num_classes (int): Number of classes in the segmentation task.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean F1 score across all classes.\n",
    "    \"\"\"\n",
    "    # Flatten predictions and labels\n",
    "    preds_flat = preds.view(-1)\n",
    "    labels_flat = labels.view(-1)\n",
    "\n",
    "    # Calculate the F1 score for each class\n",
    "    dice_scores = []\n",
    "    for i in range(num_classes):\n",
    "        class_preds = (preds_flat == i)\n",
    "        class_labels = (labels_flat == i)\n",
    "\n",
    "        # Calculate F1 score for each class\n",
    "        dice = f1_score(class_labels.cpu().numpy(), class_preds.cpu().numpy(), labels=[True], average='binary')\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "    # Return the mean F1 score\n",
    "    return np.mean(dice_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31616649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score_per_class(preds, labels, num_classes):\n",
    "    \"\"\"Calculate the Dice score for each class.\n",
    "\n",
    "    Args:\n",
    "        preds (np.ndarray): Predicted labels from the model.\n",
    "        labels (np.ndarray): Ground truth labels.\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Dice score for each class.\n",
    "    \"\"\"\n",
    "    dice_scores = []\n",
    "    for i in range(num_classes):\n",
    "        class_preds = (preds == i)\n",
    "        class_labels = (labels == i)\n",
    "\n",
    "        # Calculate Dice score for each class\n",
    "        intersection = np.logical_and(class_labels.cpu().numpy().flatten(), class_preds.cpu().numpy().flatten()).sum()\n",
    "        union = np.logical_or(class_labels.cpu().numpy().flatten(), class_preds.cpu().numpy().flatten()).sum()\n",
    "        dice = (2 * intersection) / (union + intersection + 1e-8)  # Add epsilon to avoid division by zero\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "    return np.array(dice_scores)\n",
    "\n",
    "\n",
    "def dice_score(preds, labels, num_classes):\n",
    "    \"\"\"Calculate the mean Dice score for multiple classes.\n",
    "\n",
    "    Args:\n",
    "        preds (np.ndarray): Predicted labels from the model.\n",
    "        labels (np.ndarray): Ground truth labels.\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Dice score across all classes.\n",
    "    \"\"\"\n",
    "    # Calculate Dice score for each class\n",
    "    dice_scores = dice_score_per_class(preds, labels, num_classes)\n",
    "\n",
    "    # Return the mean Dice score\n",
    "    return np.mean(dice_scores)\n",
    "\n",
    "\n",
    "# def mean_iou(preds, labels, num_classes):\n",
    "#     \"\"\"Calculate the mean Intersection over Union (IoU) for multiple classes.\n",
    "\n",
    "#     Args:\n",
    "#         preds (torch.Tensor): Predicted labels (logits) from the model.\n",
    "#         labels (torch.Tensor): Ground truth labels.\n",
    "#         num_classes (int): Number of classes in the segmentation task.\n",
    "\n",
    "#     Returns:\n",
    "#         float: Mean IoU across all classes.\n",
    "#     \"\"\"\n",
    "#     # Flatten predictions and labels\n",
    "#     preds_flat = preds.view(-1)\n",
    "#     labels_flat = labels.view(-1)\n",
    "\n",
    "#     # Check that the number of elements in the flattened predictions\n",
    "#     # and labels are equal\n",
    "#     if preds_flat.shape[0] != labels_flat.shape[0]:\n",
    "#         raise ValueError(f\"Predictions and labels have mismatched shapes: \"\n",
    "#                          f\"{preds_flat.shape} vs {labels_flat.shape}\")\n",
    "\n",
    "#     # Calculate the Jaccard score for each class\n",
    "#     iou = jaccard_score(labels_flat.cpu().numpy(), preds_flat.cpu().numpy(),\n",
    "#                         average=None, labels=range(num_classes))\n",
    "\n",
    "#     # Return the mean IoU\n",
    "#     return np.mean(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def iou_score_per_class(preds, labels, num_classes):\n",
    "    \"\"\"Calculate the Intersection over Union (IoU) score for each class.\n",
    "\n",
    "    Args:\n",
    "        preds (np.ndarray): Predicted labels from the model.\n",
    "        labels (np.ndarray): Ground truth labels.\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: IoU score for each class.\n",
    "    \"\"\"\n",
    "    iou_scores = []\n",
    "    for i in range(num_classes):\n",
    "        class_preds = (preds == i)\n",
    "        class_labels = (labels == i)\n",
    "\n",
    "        # Calculate IoU score for each class\n",
    "        intersection = np.logical_and(class_labels.cpu().numpy().flatten(), class_preds.cpu().numpy().flatten()).sum()\n",
    "        union = np.logical_or(class_labels.cpu().numpy().flatten(), class_preds.cpu().numpy().flatten()).sum()\n",
    "        iou = (intersection) / (union + 1e-8)  # Add epsilon to avoid division by zero\n",
    "        iou_scores.append(iou)\n",
    "\n",
    "    return np.array(iou_scores)\n",
    "\n",
    "\n",
    "def mean_iou(preds, labels, num_classes):\n",
    "    \"\"\"Calculate the mean Intersection over Union (IoU) for multiple classes.\n",
    "\n",
    "    Args:\n",
    "        preds (np.ndarray): Predicted labels from the model.\n",
    "        labels (np.ndarray): Ground truth labels.\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean IoU across all classes.\n",
    "    \"\"\"\n",
    "    # Calculate IoU score for each class\n",
    "    iou_scores = iou_score_per_class(preds, labels, num_classes)\n",
    "\n",
    "    # Return the mean IoU\n",
    "    return np.mean(iou_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f62c8",
   "metadata": {},
   "source": [
    "# Block 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c33899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([2, 3, 256, 256]), Output Shape: torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class VisionTransformerArgs:\n",
    "    \"\"\"Data class to hold arguments for Vision Transformer model.\"\"\"\n",
    "    embed_size: int = IMG_SIZE\n",
    "    image_size: int = IMG_SIZE\n",
    "    patch_size: int = 16\n",
    "    num_heads: int = 16\n",
    "    dropout: float = 0.2\n",
    "    in_channels: int = 3\n",
    "    out_channels: int = 3\n",
    "    num_blocks: int = 12\n",
    "\n",
    "class ImageToPatches(nn.Module):\n",
    "    \"\"\"Converts an image into patches using unfolding.\"\"\"\n",
    "    def __init__(self, image_size, patch_size):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.unfold = nn.Unfold(kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input has 4 dimensions (B, C, H, W)\n",
    "        assert len(x.size()) == 4\n",
    "        y = self.unfold(x)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        return y\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    \"\"\"Embeds patches into a lower-dimensional space.\"\"\"\n",
    "    def __init__(self, in_channels, embed_size):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.embed_size = embed_size\n",
    "        self.embed_layer = nn.Linear(in_features=in_channels, out_features=embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input has 3 dimensions (B, T, C)\n",
    "        assert len(x.size()) == 3\n",
    "        B, T, C = x.size()\n",
    "        x = self.embed_layer(x)\n",
    "        return x\n",
    "\n",
    "class VisionTransformerInput(nn.Module):\n",
    "    \"\"\"Handles the input embedding for the Vision Transformer.\"\"\"\n",
    "    def __init__(self, image_size, patch_size, in_channels, embed_size):\n",
    "        super().__init__()\n",
    "        self.i2p = ImageToPatches(image_size, patch_size)\n",
    "        self.pe = PatchEmbedding(patch_size * patch_size * in_channels, embed_size)\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.position_embed = nn.Parameter(torch.randn(num_patches, embed_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.i2p(x)\n",
    "        x = self.pe(x)\n",
    "        x = x + self.position_embed\n",
    "        return x\n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    \"\"\"A simple Multi-Layer Perceptron.\"\"\"\n",
    "    def __init__(self, embed_size, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(embed_size, embed_size * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_size * 4, embed_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class SelfAttentionEncoderBlock(nn.Module):\n",
    "    \"\"\"Encoder block with self-attention mechanism.\"\"\"\n",
    "    def __init__(self, embed_size, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.mha = nn.MultiheadAttention(embed_size, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        self.mlp = MultiLayerPerceptron(embed_size, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.ln1(x)\n",
    "        x = x + self.mha(y, y, y, need_weights=False)[0]\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class OutputProjection(nn.Module):\n",
    "    \"\"\"Projects the embeddings back to the original image size.\"\"\"\n",
    "    def __init__(self, image_size, patch_size, embed_size, output_dims):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.output_dims = output_dims\n",
    "        self.projection = nn.Linear(embed_size, patch_size * patch_size * output_dims)\n",
    "        self.fold = Fold(output_size=(image_size, image_size), kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = self.projection(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fold(x)\n",
    "        return x\n",
    "\n",
    "class VisionTransformerForSegmentation(nn.Module):\n",
    "    \"\"\"Complete Vision Transformer for segmentation tasks.\"\"\"\n",
    "    def __init__(self, image_size, patch_size, in_channels, out_channels, embed_size, num_blocks, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create a list of self-attention encoder blocks\n",
    "        heads = [SelfAttentionEncoderBlock(embed_size, num_heads, dropout) for _ in range(num_blocks)]\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=in_channels),\n",
    "            VisionTransformerInput(image_size, patch_size, in_channels, embed_size),\n",
    "            nn.Sequential(*heads),\n",
    "            OutputProjection(image_size, patch_size, embed_size, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "def build_vision_transformer(args: VisionTransformerArgs):\n",
    "    \"\"\"Builds a Vision Transformer model based on the provided arguments.\n",
    "\n",
    "    Args:\n",
    "        args (VisionTransformerArgs): Arguments for the Vision Transformer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the Vision Transformer model, input shape, and output shape.\n",
    "    \"\"\"\n",
    "    x = torch.randn(2, args.in_channels, args.image_size, args.image_size)\n",
    "    vit = VisionTransformerForSegmentation(**dataclasses.asdict(args))\n",
    "    y = vit(x)\n",
    "    return vit, x.shape, y.shape\n",
    "\n",
    "# Model usage:\n",
    "vit_args = VisionTransformerArgs(embed_size=IMG_SIZE, image_size=IMG_SIZE)\n",
    "vitvs_model, input_shape, output_shape = build_vision_transformer(vit_args)\n",
    "print(f\"Input Shape: {input_shape}, Output Shape: {output_shape}\")\n",
    "model_name = 'ViTVS_block_12_iou_80.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5debd686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear the GPU memory cache to free up memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Display a summary of GPU memory usage\n",
    "# The 'device' parameter can be specified to check memory for a specific GPU\n",
    "# Set 'abbreviated' to True for a concise summary\n",
    "# The summary includes details like allocated, reserved, and cached memory\n",
    "memory_summary = torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "# Print the memory summary\n",
    "print(memory_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00dea2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformerForSegmentation(\n",
       "  (layers): Sequential(\n",
       "    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): VisionTransformerInput(\n",
       "      (i2p): ImageToPatches(\n",
       "        (unfold): Unfold(kernel_size=16, dilation=1, padding=0, stride=16)\n",
       "      )\n",
       "      (pe): PatchEmbedding(\n",
       "        (embed_layer): Linear(in_features=768, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): OutputProjection(\n",
       "      (projection): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (fold): Fold(output_size=(256, 256), kernel_size=16, dilation=1, padding=0, stride=16)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA acceleration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = vit\n",
    "model = vitvs_model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffa2aa2-bb21-41e1-9fd5-f96f269d358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/1250 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\ysz\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Epoch 1/100: 100%|██████████| 1250/1250 [14:42<00:00,  1.42batch/s, loss=0.148] \n",
      "Validation: 100%|██████████| 175/175 [02:42<00:00,  1.08batch/s, dice_score=0.825, f1_score=0.825, loss=0.0914, mean_iou=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0889 | Mean IoU: 0.7127 | Mean Dice: 0.8036 | Mean F1 Score: 0.8036\n",
      "Validation IoU improved from 0.0000 to 0.7127\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 1250/1250 [15:31<00:00,  1.34batch/s, loss=0.103] \n",
      "Validation: 100%|██████████| 175/175 [02:59<00:00,  1.02s/batch, dice_score=0.848, f1_score=0.848, loss=0.0815, mean_iou=0.76] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0775 | Mean IoU: 0.7483 | Mean Dice: 0.8353 | Mean F1 Score: 0.8353\n",
      "Validation IoU improved from 0.7127 to 0.7483\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 1250/1250 [15:48<00:00,  1.32batch/s, loss=0.0714]\n",
      "Validation: 100%|██████████| 175/175 [03:01<00:00,  1.04s/batch, dice_score=0.861, f1_score=0.861, loss=0.0733, mean_iou=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0731 | Mean IoU: 0.7580 | Mean Dice: 0.8432 | Mean F1 Score: 0.8432\n",
      "Validation IoU improved from 0.7483 to 0.7580\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 1250/1250 [14:56<00:00,  1.39batch/s, loss=0.0585]\n",
      "Validation: 100%|██████████| 175/175 [03:08<00:00,  1.07s/batch, dice_score=0.858, f1_score=0.858, loss=0.0713, mean_iou=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0714 | Mean IoU: 0.7565 | Mean Dice: 0.8419 | Mean F1 Score: 0.8419\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 1250/1250 [16:35<00:00,  1.26batch/s, loss=0.036] \n",
      "Validation: 100%|██████████| 175/175 [03:04<00:00,  1.06s/batch, dice_score=0.866, f1_score=0.866, loss=0.0695, mean_iou=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0726 | Mean IoU: 0.7526 | Mean Dice: 0.8385 | Mean F1 Score: 0.8385\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 1250/1250 [15:44<00:00,  1.32batch/s, loss=0.0776]\n",
      "Validation: 100%|██████████| 175/175 [03:01<00:00,  1.04s/batch, dice_score=0.886, f1_score=0.886, loss=0.0612, mean_iou=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0672 | Mean IoU: 0.7757 | Mean Dice: 0.8576 | Mean F1 Score: 0.8576\n",
      "Validation IoU improved from 0.7580 to 0.7757\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 1250/1250 [16:35<00:00,  1.26batch/s, loss=0.105] \n",
      "Validation: 100%|██████████| 175/175 [03:00<00:00,  1.03s/batch, dice_score=0.89, f1_score=0.89, loss=0.0571, mean_iou=0.816]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0651 | Mean IoU: 0.7791 | Mean Dice: 0.8602 | Mean F1 Score: 0.8602\n",
      "Validation IoU improved from 0.7757 to 0.7791\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 1250/1250 [15:14<00:00,  1.37batch/s, loss=0.0529]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.886, f1_score=0.886, loss=0.0588, mean_iou=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0637 | Mean IoU: 0.7859 | Mean Dice: 0.8657 | Mean F1 Score: 0.8657\n",
      "Validation IoU improved from 0.7791 to 0.7859\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 1250/1250 [13:27<00:00,  1.55batch/s, loss=0.0499]\n",
      "Validation: 100%|██████████| 175/175 [02:26<00:00,  1.19batch/s, dice_score=0.897, f1_score=0.897, loss=0.0553, mean_iou=0.826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0636 | Mean IoU: 0.7842 | Mean Dice: 0.8641 | Mean F1 Score: 0.8641\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 1250/1250 [12:06<00:00,  1.72batch/s, loss=0.0505]\n",
      "Validation: 100%|██████████| 175/175 [02:26<00:00,  1.20batch/s, dice_score=0.89, f1_score=0.89, loss=0.0556, mean_iou=0.816]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0650 | Mean IoU: 0.7739 | Mean Dice: 0.8554 | Mean F1 Score: 0.8554\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 1250/1250 [12:06<00:00,  1.72batch/s, loss=0.0736]\n",
      "Validation: 100%|██████████| 175/175 [02:26<00:00,  1.19batch/s, dice_score=0.896, f1_score=0.896, loss=0.0552, mean_iou=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0624 | Mean IoU: 0.7876 | Mean Dice: 0.8666 | Mean F1 Score: 0.8666\n",
      "Validation IoU improved from 0.7859 to 0.7876\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 1250/1250 [12:07<00:00,  1.72batch/s, loss=0.0492]\n",
      "Validation: 100%|██████████| 175/175 [02:25<00:00,  1.20batch/s, dice_score=0.896, f1_score=0.896, loss=0.0556, mean_iou=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0624 | Mean IoU: 0.7914 | Mean Dice: 0.8695 | Mean F1 Score: 0.8695\n",
      "Validation IoU improved from 0.7876 to 0.7914\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 1250/1250 [13:31<00:00,  1.54batch/s, loss=0.0509]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.904, f1_score=0.904, loss=0.0525, mean_iou=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0623 | Mean IoU: 0.7921 | Mean Dice: 0.8701 | Mean F1 Score: 0.8701\n",
      "Validation IoU improved from 0.7914 to 0.7921\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 1250/1250 [14:13<00:00,  1.46batch/s, loss=0.0542]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.02batch/s, dice_score=0.89, f1_score=0.89, loss=0.0584, mean_iou=0.816]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0625 | Mean IoU: 0.7941 | Mean Dice: 0.8717 | Mean F1 Score: 0.8717\n",
      "Validation IoU improved from 0.7921 to 0.7941\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 1250/1250 [14:14<00:00,  1.46batch/s, loss=0.0831]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.888, f1_score=0.888, loss=0.0562, mean_iou=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0623 | Mean IoU: 0.7920 | Mean Dice: 0.8702 | Mean F1 Score: 0.8702\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 1250/1250 [12:21<00:00,  1.69batch/s, loss=0.0453]\n",
      "Validation: 100%|██████████| 175/175 [02:24<00:00,  1.21batch/s, dice_score=0.881, f1_score=0.881, loss=0.06, mean_iou=0.804]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0634 | Mean IoU: 0.7875 | Mean Dice: 0.8667 | Mean F1 Score: 0.8667\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 1250/1250 [11:56<00:00,  1.75batch/s, loss=0.0663]\n",
      "Validation: 100%|██████████| 175/175 [02:25<00:00,  1.21batch/s, dice_score=0.903, f1_score=0.903, loss=0.0525, mean_iou=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0608 | Mean IoU: 0.7981 | Mean Dice: 0.8746 | Mean F1 Score: 0.8746\n",
      "Validation IoU improved from 0.7941 to 0.7981\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 1250/1250 [11:58<00:00,  1.74batch/s, loss=0.0623]\n",
      "Validation: 100%|██████████| 175/175 [02:25<00:00,  1.20batch/s, dice_score=0.905, f1_score=0.905, loss=0.0554, mean_iou=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0615 | Mean IoU: 0.7987 | Mean Dice: 0.8755 | Mean F1 Score: 0.8755\n",
      "Validation IoU improved from 0.7981 to 0.7987\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 1250/1250 [12:10<00:00,  1.71batch/s, loss=0.0646]\n",
      "Validation: 100%|██████████| 175/175 [02:30<00:00,  1.16batch/s, dice_score=0.898, f1_score=0.898, loss=0.0542, mean_iou=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0610 | Mean IoU: 0.7930 | Mean Dice: 0.8704 | Mean F1 Score: 0.8704\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 1250/1250 [14:39<00:00,  1.42batch/s, loss=0.0249]\n",
      "Validation: 100%|██████████| 175/175 [02:54<00:00,  1.00batch/s, dice_score=0.897, f1_score=0.897, loss=0.0533, mean_iou=0.826] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0622 | Mean IoU: 0.7964 | Mean Dice: 0.8731 | Mean F1 Score: 0.8731\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 1250/1250 [14:36<00:00,  1.43batch/s, loss=0.0383]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.906, f1_score=0.906, loss=0.0513, mean_iou=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0611 | Mean IoU: 0.7959 | Mean Dice: 0.8727 | Mean F1 Score: 0.8727\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 1250/1250 [14:32<00:00,  1.43batch/s, loss=0.048] \n",
      "Validation: 100%|██████████| 175/175 [02:52<00:00,  1.01batch/s, dice_score=0.903, f1_score=0.903, loss=0.0499, mean_iou=0.834] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0622 | Mean IoU: 0.7922 | Mean Dice: 0.8697 | Mean F1 Score: 0.8697\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 1250/1250 [14:12<00:00,  1.47batch/s, loss=0.0476]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.89, f1_score=0.89, loss=0.0534, mean_iou=0.816]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0620 | Mean IoU: 0.7896 | Mean Dice: 0.8678 | Mean F1 Score: 0.8678\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 1250/1250 [14:03<00:00,  1.48batch/s, loss=0.0385]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.907, f1_score=0.907, loss=0.0495, mean_iou=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0608 | Mean IoU: 0.7976 | Mean Dice: 0.8741 | Mean F1 Score: 0.8741\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 1250/1250 [14:03<00:00,  1.48batch/s, loss=0.0511]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.904, f1_score=0.904, loss=0.0535, mean_iou=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0608 | Mean IoU: 0.8026 | Mean Dice: 0.8784 | Mean F1 Score: 0.8784\n",
      "Validation IoU improved from 0.7987 to 0.8026\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 1250/1250 [14:51<00:00,  1.40batch/s, loss=0.0531]\n",
      "Validation: 100%|██████████| 175/175 [02:59<00:00,  1.02s/batch, dice_score=0.908, f1_score=0.908, loss=0.0497, mean_iou=0.841] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0595 | Mean IoU: 0.8030 | Mean Dice: 0.8785 | Mean F1 Score: 0.8785\n",
      "Validation IoU improved from 0.8026 to 0.8030\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 1250/1250 [15:06<00:00,  1.38batch/s, loss=0.0341]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.909, f1_score=0.909, loss=0.0479, mean_iou=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0610 | Mean IoU: 0.8026 | Mean Dice: 0.8780 | Mean F1 Score: 0.8780\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 1250/1250 [12:26<00:00,  1.67batch/s, loss=0.0467]\n",
      "Validation: 100%|██████████| 175/175 [02:34<00:00,  1.14batch/s, dice_score=0.905, f1_score=0.905, loss=0.0507, mean_iou=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0597 | Mean IoU: 0.8040 | Mean Dice: 0.8792 | Mean F1 Score: 0.8792\n",
      "Validation IoU improved from 0.8030 to 0.8040\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 1250/1250 [15:03<00:00,  1.38batch/s, loss=0.0524]\n",
      "Validation: 100%|██████████| 175/175 [02:52<00:00,  1.01batch/s, dice_score=0.905, f1_score=0.905, loss=0.0494, mean_iou=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0602 | Mean IoU: 0.8029 | Mean Dice: 0.8782 | Mean F1 Score: 0.8782\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 1250/1250 [14:53<00:00,  1.40batch/s, loss=0.0593]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.903, f1_score=0.903, loss=0.05, mean_iou=0.834]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0612 | Mean IoU: 0.8022 | Mean Dice: 0.8773 | Mean F1 Score: 0.8773\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 1250/1250 [13:58<00:00,  1.49batch/s, loss=0.0705]\n",
      "Validation: 100%|██████████| 175/175 [02:24<00:00,  1.21batch/s, dice_score=0.904, f1_score=0.904, loss=0.0502, mean_iou=0.835] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0611 | Mean IoU: 0.7998 | Mean Dice: 0.8755 | Mean F1 Score: 0.8755\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 1250/1250 [11:53<00:00,  1.75batch/s, loss=0.045] \n",
      "Validation: 100%|██████████| 175/175 [02:24<00:00,  1.22batch/s, dice_score=0.909, f1_score=0.909, loss=0.0475, mean_iou=0.844] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0607 | Mean IoU: 0.8021 | Mean Dice: 0.8777 | Mean F1 Score: 0.8777\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 1250/1250 [12:57<00:00,  1.61batch/s, loss=0.051] \n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.906, f1_score=0.906, loss=0.0504, mean_iou=0.839] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0604 | Mean IoU: 0.8061 | Mean Dice: 0.8809 | Mean F1 Score: 0.8809\n",
      "Validation IoU improved from 0.8040 to 0.8061\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 1250/1250 [14:13<00:00,  1.46batch/s, loss=0.0746]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.901, f1_score=0.901, loss=0.0512, mean_iou=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0596 | Mean IoU: 0.8058 | Mean Dice: 0.8804 | Mean F1 Score: 0.8804\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 1250/1250 [14:08<00:00,  1.47batch/s, loss=0.0394]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.04batch/s, dice_score=0.909, f1_score=0.909, loss=0.0482, mean_iou=0.843] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0602 | Mean IoU: 0.8066 | Mean Dice: 0.8809 | Mean F1 Score: 0.8809\n",
      "Validation IoU improved from 0.8061 to 0.8066\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 1250/1250 [14:19<00:00,  1.45batch/s, loss=0.0315]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.9, f1_score=0.9, loss=0.0519, mean_iou=0.83]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0608 | Mean IoU: 0.8022 | Mean Dice: 0.8774 | Mean F1 Score: 0.8774\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 1250/1250 [14:47<00:00,  1.41batch/s, loss=0.0449]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.897, f1_score=0.897, loss=0.0534, mean_iou=0.826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0625 | Mean IoU: 0.8022 | Mean Dice: 0.8774 | Mean F1 Score: 0.8774\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 1250/1250 [14:34<00:00,  1.43batch/s, loss=0.0379]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.904, f1_score=0.904, loss=0.0507, mean_iou=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0604 | Mean IoU: 0.8054 | Mean Dice: 0.8800 | Mean F1 Score: 0.8800\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 1250/1250 [13:06<00:00,  1.59batch/s, loss=0.0328]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.905, f1_score=0.905, loss=0.0503, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0609 | Mean IoU: 0.8036 | Mean Dice: 0.8788 | Mean F1 Score: 0.8788\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 1250/1250 [14:41<00:00,  1.42batch/s, loss=0.0448]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.02batch/s, dice_score=0.902, f1_score=0.902, loss=0.0503, mean_iou=0.834] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0608 | Mean IoU: 0.8042 | Mean Dice: 0.8791 | Mean F1 Score: 0.8791\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 1250/1250 [15:10<00:00,  1.37batch/s, loss=0.0471]\n",
      "Validation: 100%|██████████| 175/175 [02:59<00:00,  1.02s/batch, dice_score=0.905, f1_score=0.905, loss=0.0508, mean_iou=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0610 | Mean IoU: 0.8062 | Mean Dice: 0.8808 | Mean F1 Score: 0.8808\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 1250/1250 [15:12<00:00,  1.37batch/s, loss=0.0213]\n",
      "Validation: 100%|██████████| 175/175 [02:57<00:00,  1.02s/batch, dice_score=0.91, f1_score=0.91, loss=0.048, mean_iou=0.844]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0608 | Mean IoU: 0.8058 | Mean Dice: 0.8804 | Mean F1 Score: 0.8804\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 1250/1250 [14:29<00:00,  1.44batch/s, loss=0.0361]\n",
      "Validation: 100%|██████████| 175/175 [02:52<00:00,  1.01batch/s, dice_score=0.902, f1_score=0.902, loss=0.0525, mean_iou=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0615 | Mean IoU: 0.8070 | Mean Dice: 0.8811 | Mean F1 Score: 0.8811\n",
      "Validation IoU improved from 0.8066 to 0.8070\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 1250/1250 [15:13<00:00,  1.37batch/s, loss=0.0256]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.91, f1_score=0.91, loss=0.0482, mean_iou=0.845]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0609 | Mean IoU: 0.8086 | Mean Dice: 0.8826 | Mean F1 Score: 0.8826\n",
      "Validation IoU improved from 0.8070 to 0.8086\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 1250/1250 [14:32<00:00,  1.43batch/s, loss=0.0357]\n",
      "Validation: 100%|██████████| 175/175 [02:52<00:00,  1.02batch/s, dice_score=0.909, f1_score=0.909, loss=0.0478, mean_iou=0.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0601 | Mean IoU: 0.8066 | Mean Dice: 0.8810 | Mean F1 Score: 0.8810\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 1250/1250 [14:19<00:00,  1.45batch/s, loss=0.0346]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.903, f1_score=0.903, loss=0.0519, mean_iou=0.834] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0617 | Mean IoU: 0.8084 | Mean Dice: 0.8822 | Mean F1 Score: 0.8822\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 1250/1250 [14:19<00:00,  1.45batch/s, loss=0.0518]\n",
      "Validation: 100%|██████████| 175/175 [02:35<00:00,  1.13batch/s, dice_score=0.908, f1_score=0.908, loss=0.0481, mean_iou=0.842] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0609 | Mean IoU: 0.8076 | Mean Dice: 0.8817 | Mean F1 Score: 0.8817\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 1250/1250 [14:28<00:00,  1.44batch/s, loss=0.0324]\n",
      "Validation: 100%|██████████| 175/175 [02:57<00:00,  1.01s/batch, dice_score=0.906, f1_score=0.906, loss=0.0497, mean_iou=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0610 | Mean IoU: 0.8076 | Mean Dice: 0.8817 | Mean F1 Score: 0.8817\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 1250/1250 [14:55<00:00,  1.40batch/s, loss=0.0186]\n",
      "Validation: 100%|██████████| 175/175 [02:53<00:00,  1.01batch/s, dice_score=0.907, f1_score=0.907, loss=0.0484, mean_iou=0.841] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0612 | Mean IoU: 0.8086 | Mean Dice: 0.8824 | Mean F1 Score: 0.8824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 1250/1250 [14:30<00:00,  1.44batch/s, loss=0.0441]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.912, f1_score=0.912, loss=0.0481, mean_iou=0.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0618 | Mean IoU: 0.8090 | Mean Dice: 0.8828 | Mean F1 Score: 0.8828\n",
      "Validation IoU improved from 0.8086 to 0.8090\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 1250/1250 [14:38<00:00,  1.42batch/s, loss=0.0266]\n",
      "Validation: 100%|██████████| 175/175 [02:48<00:00,  1.04batch/s, dice_score=0.904, f1_score=0.904, loss=0.0524, mean_iou=0.836] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0628 | Mean IoU: 0.8055 | Mean Dice: 0.8799 | Mean F1 Score: 0.8799\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 1250/1250 [14:30<00:00,  1.44batch/s, loss=0.0459]\n",
      "Validation: 100%|██████████| 175/175 [02:34<00:00,  1.13batch/s, dice_score=0.905, f1_score=0.905, loss=0.0498, mean_iou=0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0617 | Mean IoU: 0.8050 | Mean Dice: 0.8795 | Mean F1 Score: 0.8795\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 1250/1250 [13:10<00:00,  1.58batch/s, loss=0.0539]\n",
      "Validation: 100%|██████████| 175/175 [02:52<00:00,  1.01batch/s, dice_score=0.907, f1_score=0.907, loss=0.0488, mean_iou=0.84]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0618 | Mean IoU: 0.8072 | Mean Dice: 0.8814 | Mean F1 Score: 0.8814\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 1250/1250 [14:32<00:00,  1.43batch/s, loss=0.0413]\n",
      "Validation: 100%|██████████| 175/175 [02:35<00:00,  1.13batch/s, dice_score=0.905, f1_score=0.905, loss=0.0503, mean_iou=0.838] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0621 | Mean IoU: 0.8080 | Mean Dice: 0.8820 | Mean F1 Score: 0.8820\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 1250/1250 [13:10<00:00,  1.58batch/s, loss=0.0493]\n",
      "Validation: 100%|██████████| 175/175 [02:34<00:00,  1.13batch/s, dice_score=0.908, f1_score=0.908, loss=0.0492, mean_iou=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0623 | Mean IoU: 0.8051 | Mean Dice: 0.8798 | Mean F1 Score: 0.8798\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 1250/1250 [13:09<00:00,  1.58batch/s, loss=0.0194]\n",
      "Validation: 100%|██████████| 175/175 [02:34<00:00,  1.13batch/s, dice_score=0.911, f1_score=0.911, loss=0.0481, mean_iou=0.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0615 | Mean IoU: 0.8082 | Mean Dice: 0.8821 | Mean F1 Score: 0.8821\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 1250/1250 [13:39<00:00,  1.53batch/s, loss=0.072] \n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.904, f1_score=0.904, loss=0.0514, mean_iou=0.836] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0619 | Mean IoU: 0.8087 | Mean Dice: 0.8824 | Mean F1 Score: 0.8824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 1250/1250 [13:25<00:00,  1.55batch/s, loss=0.0473]\n",
      "Validation: 100%|██████████| 175/175 [02:36<00:00,  1.12batch/s, dice_score=0.909, f1_score=0.909, loss=0.0485, mean_iou=0.843] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0620 | Mean IoU: 0.8087 | Mean Dice: 0.8825 | Mean F1 Score: 0.8825\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 1250/1250 [14:10<00:00,  1.47batch/s, loss=0.0278]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.907, f1_score=0.907, loss=0.0499, mean_iou=0.841] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0621 | Mean IoU: 0.8085 | Mean Dice: 0.8824 | Mean F1 Score: 0.8824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 1250/1250 [14:34<00:00,  1.43batch/s, loss=0.026] \n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.02batch/s, dice_score=0.908, f1_score=0.908, loss=0.0492, mean_iou=0.842] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0624 | Mean IoU: 0.8094 | Mean Dice: 0.8831 | Mean F1 Score: 0.8831\n",
      "Validation IoU improved from 0.8090 to 0.8094\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 1250/1250 [14:54<00:00,  1.40batch/s, loss=0.0503]\n",
      "Validation: 100%|██████████| 175/175 [02:44<00:00,  1.06batch/s, dice_score=0.906, f1_score=0.906, loss=0.0505, mean_iou=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0625 | Mean IoU: 0.8076 | Mean Dice: 0.8816 | Mean F1 Score: 0.8816\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 1250/1250 [12:34<00:00,  1.66batch/s, loss=0.0514]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.903, f1_score=0.903, loss=0.0533, mean_iou=0.834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0634 | Mean IoU: 0.8080 | Mean Dice: 0.8819 | Mean F1 Score: 0.8819\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 1250/1250 [14:21<00:00,  1.45batch/s, loss=0.0408]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.902, f1_score=0.902, loss=0.0553, mean_iou=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0640 | Mean IoU: 0.8074 | Mean Dice: 0.8814 | Mean F1 Score: 0.8814\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 1250/1250 [14:07<00:00,  1.47batch/s, loss=0.0309]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.04batch/s, dice_score=0.909, f1_score=0.909, loss=0.0498, mean_iou=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0634 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 1250/1250 [14:20<00:00,  1.45batch/s, loss=0.0505]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.908, f1_score=0.908, loss=0.0525, mean_iou=0.841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0636 | Mean IoU: 0.8083 | Mean Dice: 0.8821 | Mean F1 Score: 0.8821\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 1250/1250 [14:32<00:00,  1.43batch/s, loss=0.0504] \n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.04batch/s, dice_score=0.905, f1_score=0.905, loss=0.052, mean_iou=0.838] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0632 | Mean IoU: 0.8094 | Mean Dice: 0.8831 | Mean F1 Score: 0.8831\n",
      "Validation IoU improved from 0.8094 to 0.8094\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 1250/1250 [14:32<00:00,  1.43batch/s, loss=0.052] \n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.908, f1_score=0.908, loss=0.0515, mean_iou=0.841] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0634 | Mean IoU: 0.8086 | Mean Dice: 0.8824 | Mean F1 Score: 0.8824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 1250/1250 [14:29<00:00,  1.44batch/s, loss=0.0417]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.904, f1_score=0.904, loss=0.0517, mean_iou=0.836] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0632 | Mean IoU: 0.8081 | Mean Dice: 0.8820 | Mean F1 Score: 0.8820\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 1250/1250 [14:20<00:00,  1.45batch/s, loss=0.0461]\n",
      "Validation: 100%|██████████| 175/175 [02:48<00:00,  1.04batch/s, dice_score=0.904, f1_score=0.904, loss=0.0533, mean_iou=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0640 | Mean IoU: 0.8091 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 1250/1250 [14:01<00:00,  1.49batch/s, loss=0.035] \n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.908, f1_score=0.908, loss=0.0506, mean_iou=0.841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0643 | Mean IoU: 0.8086 | Mean Dice: 0.8824 | Mean F1 Score: 0.8824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 1250/1250 [14:47<00:00,  1.41batch/s, loss=0.0315]\n",
      "Validation: 100%|██████████| 175/175 [02:56<00:00,  1.01s/batch, dice_score=0.905, f1_score=0.905, loss=0.0533, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0652 | Mean IoU: 0.8093 | Mean Dice: 0.8828 | Mean F1 Score: 0.8828\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 1250/1250 [14:52<00:00,  1.40batch/s, loss=0.0354]\n",
      "Validation: 100%|██████████| 175/175 [02:58<00:00,  1.02s/batch, dice_score=0.905, f1_score=0.905, loss=0.0528, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0637 | Mean IoU: 0.8091 | Mean Dice: 0.8828 | Mean F1 Score: 0.8828\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 1250/1250 [14:59<00:00,  1.39batch/s, loss=0.0368]\n",
      "Validation: 100%|██████████| 175/175 [02:58<00:00,  1.02s/batch, dice_score=0.905, f1_score=0.905, loss=0.0518, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0640 | Mean IoU: 0.8088 | Mean Dice: 0.8826 | Mean F1 Score: 0.8826\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 1250/1250 [15:07<00:00,  1.38batch/s, loss=0.0176]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.907, f1_score=0.907, loss=0.0512, mean_iou=0.841] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0646 | Mean IoU: 0.8086 | Mean Dice: 0.8825 | Mean F1 Score: 0.8825\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 1250/1250 [12:08<00:00,  1.72batch/s, loss=0.0243]\n",
      "Validation: 100%|██████████| 175/175 [02:44<00:00,  1.06batch/s, dice_score=0.909, f1_score=0.909, loss=0.0505, mean_iou=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0657 | Mean IoU: 0.8092 | Mean Dice: 0.8828 | Mean F1 Score: 0.8828\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 1250/1250 [15:02<00:00,  1.38batch/s, loss=0.0532]\n",
      "Validation: 100%|██████████| 175/175 [02:53<00:00,  1.01batch/s, dice_score=0.906, f1_score=0.906, loss=0.0517, mean_iou=0.839] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0644 | Mean IoU: 0.8082 | Mean Dice: 0.8821 | Mean F1 Score: 0.8821\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 1250/1250 [15:13<00:00,  1.37batch/s, loss=0.0371]\n",
      "Validation: 100%|██████████| 175/175 [02:58<00:00,  1.02s/batch, dice_score=0.905, f1_score=0.905, loss=0.0525, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0654 | Mean IoU: 0.8084 | Mean Dice: 0.8821 | Mean F1 Score: 0.8821\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 1250/1250 [15:18<00:00,  1.36batch/s, loss=0.0388]\n",
      "Validation: 100%|██████████| 175/175 [02:58<00:00,  1.02s/batch, dice_score=0.905, f1_score=0.905, loss=0.0523, mean_iou=0.838] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0653 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 1250/1250 [14:59<00:00,  1.39batch/s, loss=0.0288]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.904, f1_score=0.904, loss=0.0549, mean_iou=0.836] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0657 | Mean IoU: 0.8082 | Mean Dice: 0.8820 | Mean F1 Score: 0.8820\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 1250/1250 [14:22<00:00,  1.45batch/s, loss=0.0407]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.904, f1_score=0.904, loss=0.0548, mean_iou=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0659 | Mean IoU: 0.8084 | Mean Dice: 0.8822 | Mean F1 Score: 0.8822\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 1250/1250 [14:26<00:00,  1.44batch/s, loss=0.0229]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.905, f1_score=0.905, loss=0.0543, mean_iou=0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0659 | Mean IoU: 0.8092 | Mean Dice: 0.8828 | Mean F1 Score: 0.8828\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 1250/1250 [14:23<00:00,  1.45batch/s, loss=0.0191]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.906, f1_score=0.906, loss=0.0536, mean_iou=0.839] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0656 | Mean IoU: 0.8095 | Mean Dice: 0.8830 | Mean F1 Score: 0.8830\n",
      "Validation IoU improved from 0.8094 to 0.8095\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 1250/1250 [14:09<00:00,  1.47batch/s, loss=0.0389]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.906, f1_score=0.906, loss=0.0532, mean_iou=0.839] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0660 | Mean IoU: 0.8088 | Mean Dice: 0.8824 | Mean F1 Score: 0.8824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 1250/1250 [14:00<00:00,  1.49batch/s, loss=0.0123]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.905, f1_score=0.905, loss=0.0534, mean_iou=0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0663 | Mean IoU: 0.8076 | Mean Dice: 0.8815 | Mean F1 Score: 0.8815\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 1250/1250 [13:18<00:00,  1.57batch/s, loss=0.0426] \n",
      "Validation: 100%|██████████| 175/175 [02:25<00:00,  1.20batch/s, dice_score=0.904, f1_score=0.904, loss=0.0551, mean_iou=0.836] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0660 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 1250/1250 [11:59<00:00,  1.74batch/s, loss=0.0211]\n",
      "Validation: 100%|██████████| 175/175 [02:24<00:00,  1.21batch/s, dice_score=0.907, f1_score=0.907, loss=0.0525, mean_iou=0.84]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0664 | Mean IoU: 0.8099 | Mean Dice: 0.8834 | Mean F1 Score: 0.8834\n",
      "Validation IoU improved from 0.8095 to 0.8099\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 1250/1250 [13:12<00:00,  1.58batch/s, loss=0.0307]\n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.907, f1_score=0.907, loss=0.0526, mean_iou=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0661 | Mean IoU: 0.8097 | Mean Dice: 0.8832 | Mean F1 Score: 0.8832\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 1250/1250 [13:56<00:00,  1.49batch/s, loss=0.0186] \n",
      "Validation: 100%|██████████| 175/175 [02:49<00:00,  1.03batch/s, dice_score=0.906, f1_score=0.906, loss=0.0541, mean_iou=0.838] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0668 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 1250/1250 [14:05<00:00,  1.48batch/s, loss=0.0328]\n",
      "Validation: 100%|██████████| 175/175 [02:52<00:00,  1.02batch/s, dice_score=0.907, f1_score=0.907, loss=0.0519, mean_iou=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0667 | Mean IoU: 0.8085 | Mean Dice: 0.8823 | Mean F1 Score: 0.8823\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 1250/1250 [12:36<00:00,  1.65batch/s, loss=0.0415]\n",
      "Validation: 100%|██████████| 175/175 [02:26<00:00,  1.20batch/s, dice_score=0.906, f1_score=0.906, loss=0.0531, mean_iou=0.839] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0669 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 1250/1250 [14:08<00:00,  1.47batch/s, loss=0.0216]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.903, f1_score=0.903, loss=0.0557, mean_iou=0.835] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0666 | Mean IoU: 0.8087 | Mean Dice: 0.8825 | Mean F1 Score: 0.8825\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 1250/1250 [15:02<00:00,  1.38batch/s, loss=0.0286]\n",
      "Validation: 100%|██████████| 175/175 [02:59<00:00,  1.03s/batch, dice_score=0.905, f1_score=0.905, loss=0.0536, mean_iou=0.838] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0666 | Mean IoU: 0.8095 | Mean Dice: 0.8831 | Mean F1 Score: 0.8831\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 1250/1250 [15:24<00:00,  1.35batch/s, loss=0.0217] \n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.906, f1_score=0.906, loss=0.0536, mean_iou=0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0665 | Mean IoU: 0.8095 | Mean Dice: 0.8831 | Mean F1 Score: 0.8831\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 1250/1250 [14:52<00:00,  1.40batch/s, loss=0.0368]\n",
      "Validation: 100%|██████████| 175/175 [03:00<00:00,  1.03s/batch, dice_score=0.906, f1_score=0.906, loss=0.0542, mean_iou=0.839] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0671 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 1250/1250 [14:40<00:00,  1.42batch/s, loss=0.0254]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.905, f1_score=0.905, loss=0.0543, mean_iou=0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0671 | Mean IoU: 0.8095 | Mean Dice: 0.8831 | Mean F1 Score: 0.8831\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 1250/1250 [14:07<00:00,  1.48batch/s, loss=0.0301]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.905, f1_score=0.905, loss=0.0548, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0671 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 1250/1250 [14:15<00:00,  1.46batch/s, loss=0.0364]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.906, f1_score=0.906, loss=0.0539, mean_iou=0.838] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0672 | Mean IoU: 0.8089 | Mean Dice: 0.8826 | Mean F1 Score: 0.8826\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 1250/1250 [14:30<00:00,  1.44batch/s, loss=0.0356]\n",
      "Validation: 100%|██████████| 175/175 [02:50<00:00,  1.03batch/s, dice_score=0.905, f1_score=0.905, loss=0.0545, mean_iou=0.837] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0669 | Mean IoU: 0.8093 | Mean Dice: 0.8829 | Mean F1 Score: 0.8829\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 1250/1250 [14:26<00:00,  1.44batch/s, loss=0.0208]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.905, f1_score=0.905, loss=0.0545, mean_iou=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0670 | Mean IoU: 0.8093 | Mean Dice: 0.8829 | Mean F1 Score: 0.8829\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 1250/1250 [14:12<00:00,  1.47batch/s, loss=0.0168]\n",
      "Validation: 100%|██████████| 175/175 [02:51<00:00,  1.02batch/s, dice_score=0.906, f1_score=0.906, loss=0.0534, mean_iou=0.839] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0672 | Mean IoU: 0.8090 | Mean Dice: 0.8827 | Mean F1 Score: 0.8827\n",
      "Loaded the best model weights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "num_epochs = 100\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=2,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "mean_ious = []\n",
    "mean_dices = []\n",
    "mean_f1 = []\n",
    "\n",
    "# Placeholder for best mean IoU and best model weights\n",
    "best_iou = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(\"\\n\")\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "    total_loss_train = 0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n",
    "    for batch in train_iterator:\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()  \n",
    "\n",
    "        # Remove the channel dimension from the masks tensor\n",
    "        masks = masks.squeeze(1) \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass inputs to the model\n",
    "        outputs = model(images)\n",
    "        \n",
    "        softmax = nn.functional.log_softmax(outputs, dim=1)\n",
    "\n",
    "        # Ensure the masks have the correct shape\n",
    "        masks = masks.squeeze(1)  # Squeeze extra dimensions if present\n",
    "\n",
    "        loss = nn.functional.nll_loss(softmax, masks.long())\n",
    "\n",
    "        total_loss_train += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        # outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        num_batches += 1\n",
    "        \n",
    "        train_iterator.set_postfix(loss=loss.item())\n",
    "    train_loss = total_loss_train / num_batches\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation loop for each epoch\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "    total_f1 = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_iterator = tqdm(valid_loader, desc=\"Validation\", unit=\"batch\")\n",
    "        for batch in valid_iterator:\n",
    "            images, masks = batch\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).long()\n",
    "\n",
    "            # Remove the channel dimension from the masks tensor\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "            # Pass inputs to the model\n",
    "            outputs = model(images)\n",
    "\n",
    "            softmax = nn.functional.log_softmax(outputs, dim=1)\n",
    "\n",
    "            # Ensure the masks have the correct shape\n",
    "            masks = masks.squeeze(1)  # Squeeze extra dimensions if present\n",
    "\n",
    "            # Calculate the CrossEntropyLoss\n",
    "            loss = nn.functional.nll_loss(softmax, masks.long())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get the logits from the model and apply argmax to get the predictions\n",
    "            # outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            preds = torch.unsqueeze(preds, dim=1)\n",
    "\n",
    "            preds = preds.view(-1)\n",
    "            masks = masks.view(-1)\n",
    "\n",
    "            # Compute IoU and Dice Score\n",
    "            iou = mean_iou(preds, masks, 2)\n",
    "            dice = dice_score(preds, masks, 2)\n",
    "            f1 = F1_score(preds, masks, 2)\n",
    "            total_iou += iou\n",
    "            total_dice += dice\n",
    "            total_f1 += f1\n",
    "            num_batches += 1\n",
    "\n",
    "            valid_iterator.set_postfix(loss=loss.item(), mean_iou=iou, dice_score=dice, f1_score=f1)\n",
    "            \n",
    "\n",
    "    epoch_loss = total_loss / num_batches\n",
    "    epoch_iou = total_iou / num_batches\n",
    "    epoch_dice = total_dice / num_batches\n",
    "    epoch_f1 = total_f1 / num_batches\n",
    "    \n",
    "    val_losses.append(epoch_loss)\n",
    "    mean_ious.append(epoch_iou)\n",
    "    mean_dices.append(epoch_dice)\n",
    "    mean_f1.append(epoch_f1)\n",
    "\n",
    "    print(f\"Validation => Mean Loss: {epoch_loss:.4f} | Mean IoU: {epoch_iou:.4f} | Mean Dice: {epoch_dice:.4f} | Mean F1 Score: {epoch_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # Check for improvement and save the best model weights based on IoU\n",
    "    if epoch_iou > best_iou:\n",
    "        print(f\"Validation IoU improved from {best_iou:.4f} to {epoch_iou:.4f}\")\n",
    "        best_iou = epoch_iou\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, model_name)\n",
    "\n",
    "# After all epochs, load the best model weights - optional\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "print(\"Loaded the best model weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14e3bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformerForSegmentation(\n",
       "  (layers): Sequential(\n",
       "    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): VisionTransformerInput(\n",
       "      (i2p): ImageToPatches(\n",
       "        (unfold): Unfold(kernel_size=16, dilation=1, padding=0, stride=16)\n",
       "      )\n",
       "      (pe): PatchEmbedding(\n",
       "        (embed_layer): Linear(in_features=768, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): SelfAttentionEncoderBlock(\n",
       "        (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MultiLayerPerceptron(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): OutputProjection(\n",
       "      (projection): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (fold): Fold(output_size=(256, 256), kernel_size=16, dilation=1, padding=0, stride=16)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_name = \"unet-6v_95.pt\" \n",
    "model.load_state_dict(torch.load(model_name, map_location=torch.device(\"cpu\")))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b4bb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "\n",
    "# Plotting training and validation metrics\n",
    "plt.plot(range(len(train_losses)), train_losses, \"b\", label=\"train loss\")\n",
    "plt.plot(range(len(val_losses)), val_losses, \"r\", label=\"val loss\")\n",
    "plt.plot(range(len(mean_f1)), mean_f1, \"violet\", label=\"val F1 Score\")\n",
    "plt.plot(range(len(mean_dices)), mean_dices, \"g\", label=\"val dice\")\n",
    "plt.plot(range(len(mean_ious)), mean_ious, \"orange\", label=\"val iou\")\n",
    "\n",
    "\n",
    "plt.legend()  # Adding legend\n",
    "plt.xlabel(\"epoch\")  # Labeling x-axis with 'epoch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ec681",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0fd65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 175/175 [02:24<00:00,  1.21batch/s, dice_score=0.907, f1_score=0.907, loss=0.0525, mean_iou=0.84]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation => Mean Loss: 0.0664 | Mean IoU: 0.8099 | Mean Dice: 0.8834 | Mean F1 Score: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fValidation\n",
    "# Evaluation loop for each epoch\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "total_iou = 0\n",
    "total_dice = 0\n",
    "total_f1 = 0\n",
    "num_batches = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    valid_iterator = tqdm(valid_loader, desc=\"Validation\", unit=\"batch\")\n",
    "    for batch in valid_iterator:\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()\n",
    "\n",
    "        # Remove the channel dimension from the masks tensor\n",
    "        masks = masks.squeeze(1)\n",
    "\n",
    "        # Pass inputs to the model\n",
    "        outputs = model(images)\n",
    "\n",
    "        softmax = nn.functional.log_softmax(outputs, dim=1)\n",
    "\n",
    "        # Ensure the masks have the correct shape\n",
    "        masks = masks.squeeze(1)  # Squeeze extra dimensions if present\n",
    "\n",
    "        # Calculate the CrossEntropyLoss\n",
    "        loss = nn.functional.nll_loss(softmax, masks.long())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Get the logits from the model and apply argmax to get the predictions\n",
    "        # outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        preds = torch.unsqueeze(preds, dim=1)\n",
    "\n",
    "        preds = preds.view(-1)\n",
    "        masks = masks.view(-1)\n",
    "\n",
    "        # Compute IoU and Dice Score\n",
    "        iou = mean_iou(preds, masks, 2)\n",
    "        dice = dice_score(preds, masks, 2)\n",
    "        f1 = F1_score(preds, masks, 2)\n",
    "        total_iou += iou\n",
    "        total_dice += dice\n",
    "        total_f1 += f1\n",
    "        num_batches += 1\n",
    "\n",
    "        valid_iterator.set_postfix(loss=loss.item(), mean_iou=iou, dice_score=dice, f1_score=f1)\n",
    "        \n",
    "\n",
    "epoch_loss = total_loss / num_batches\n",
    "epoch_iou = total_iou / num_batches\n",
    "epoch_dice = total_dice / num_batches\n",
    "epoch_f1 = total_f1 / num_batches\n",
    "\n",
    "print(f\"Validation => Mean Loss: {epoch_loss:.4f} | Mean IoU: {epoch_iou:.4f} | Mean Dice: {epoch_dice:.4f} | Mean F1 Score: {epoch_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38fc2505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8099385153362466, 0.8834011419184735, 0.8834011419185674)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_iou, epoch_dice, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018f5e8",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2453fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/340 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 340/340 [03:58<00:00,  1.42batch/s, dice_score=0.862, f1_score=0.907, mean_iou=0.774]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test => Mean IoU: 0.8006 | Mean Dice: 0.8764 | Mean F1 Score: 0.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop for each epoch\n",
    "model.eval()\n",
    "total_iou = 0\n",
    "total_dice = 0\n",
    "total_f1 = 0\n",
    "num_batches = 0\n",
    "\n",
    "test_iterator = tqdm(test_loader, desc=\"Test\", unit=\"batch\")\n",
    "for batch in test_iterator:\n",
    "    images, masks = batch\n",
    "    images = images.to(device)\n",
    "    masks = masks.to(device).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()\n",
    "\n",
    "        # Remove the channel dimension from the masks tensor\n",
    "        masks = masks.squeeze(1)\n",
    "\n",
    "        # Pass inputs to the model\n",
    "        outputs = model(images)\n",
    "\n",
    "        softmax = nn.functional.log_softmax(outputs, dim=1)\n",
    "\n",
    "        # Ensure the masks have the correct shape\n",
    "        masks = masks.squeeze(1)  # Squeeze extra dimensions if present\n",
    "\n",
    "        # Calculate the CrossEntropyLoss\n",
    "        loss = nn.functional.nll_loss(softmax, masks.long())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Get the logits from the model and apply argmax to get the predictions\n",
    "        # outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        preds = torch.unsqueeze(preds, dim=1)\n",
    "\n",
    "    preds = preds.view(-1)\n",
    "    masks = masks.view(-1)\n",
    "\n",
    "    # Compute IoU and Dice Score\n",
    "    iou = mean_iou(preds, masks, 2)\n",
    "    dice = dice_score(preds, masks, 2)\n",
    "    total_iou += iou\n",
    "    total_dice += dice\n",
    "    total_f1 += f1\n",
    "    num_batches += 1\n",
    "\n",
    "    test_iterator.set_postfix(mean_iou=iou, dice_score=dice, f1_score=f1)\n",
    "\n",
    "test_iou = total_iou / num_batches\n",
    "test_dice = total_dice / num_batches\n",
    "test_f1 = total_f1 / num_batches\n",
    "\n",
    "print(f\"Test => Mean IoU: {test_iou:.4f} | Mean Dice: {test_dice:.4f} | Mean F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad134d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8005996963114539, 0.8763737209518718, 0.9070264458600786)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iou, test_dice, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3809ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
